---
layout: post
title:  "回调函数(callback)"
category: python
tags: python
---

回调函数其实一个很简单的概念,前几天突然看到这个概念一时间摸不到头脑.

假如你开发个爬虫,要把它做成非阻塞异步的模式,而且你事先不知道如何爬取,你会怎么做呢?最好的方法是把每个页面和函数一一对应,然后每个页面都有自己的抓取规则,这样程序就知道对应的网页该如何处理了,把它放到线程(进程)池,再做异步处理,这就是`scrapy`处理的方式.

下面是scrapy的小demo([源代码](https://github.com/taizilongxu/scrapy_jingdong/blob/master/tutorial/spiders/jd_spider.py)):

```python
class JdSpider(scrapy.Spider):
    name = "test"
    allowed_domains = ["jd.com"]
    start_urls = [
        "http://wap.jd.com/category/all.html"
    ]

    def parse(self, response):
        '获取全部分类商品'
        req = []
        for sel in response.xpath('/html/body/div[5]/div[2]/a'):
            for i in sel.xpath('@href').extract():
                if 'category' in i:
                    url = "http://wap.jd.com" + i
                    r = Request(url, callback=self.parse_category)  # 回调函数用来指定特定页面的操作.对应的是self.parse_category函数
                    req.append(r)
        return req

    def parse_category(self,response):
        '获取分类页'
        req = []
        for sel in response.xpath('/html/body/div[5]/div/a'):
            for i in sel.xpath('@href').extract():
                url = "http://wap.jd.com" + i
                r = Request(url, callback=self.parse_list)  # 回调函数
                req.append(r)
        return req
```

可以看到Request里每一个url对应一个callback,我们要做的就是把url和提取规则联系起来交给scrapy处理.

[这里](http://www.zhihu.com/question/19801131)是知乎的答案,长篇大论的写了很多,但是饶了很多弯子.

